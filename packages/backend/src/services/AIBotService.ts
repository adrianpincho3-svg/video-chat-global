import { BotMessage } from '../types';

/**
 * Servicio de bots de IA para conversaciones
 * Soporta OpenAI y Anthropic Claude
 */
export class AIBotService {
  private conversations: Map<string, BotMessage[]>;
  private aiService: 'openai' | 'anthropic' | 'mock';
  private apiKey: string | undefined;

  constructor() {
    this.conversations = new Map();
    
    // Configurar servicio de IA
    const configuredService = process.env.AI_SERVICE;
    if (configuredService === 'openai' || configuredService === 'anthropic') {
      this.aiService = configuredService;
    } else {
      this.aiService = 'mock';
    }
    
    this.apiKey = this.aiService === 'openai' 
      ? process.env.OPENAI_API_KEY 
      : process.env.ANTHROPIC_API_KEY;

    if (this.aiService !== 'mock' && !this.apiKey) {
      console.warn('âš ï¸ No se configurÃ³ API key para IA. Usando modo mock.');
      this.aiService = 'mock';
    }

    console.log(`ğŸ¤– AI Bot Service inicializado (modo: ${this.aiService})`);
  }

  /**
   * Inicializa una conversaciÃ³n con un bot
   */
  async initializeConversation(sessionId: string): Promise<void> {
    const systemMessage: BotMessage = {
      role: 'assistant',
      content: this.getSystemPrompt(),
    };

    this.conversations.set(sessionId, [systemMessage]);
    console.log(`âœ… ConversaciÃ³n con bot inicializada: ${sessionId}`);
  }

  /**
   * Genera una respuesta del bot
   */
  async generateResponse(sessionId: string, userMessage: string): Promise<string> {
    let conversation = this.conversations.get(sessionId);

    // Si no existe la conversaciÃ³n, inicializarla
    if (!conversation) {
      await this.initializeConversation(sessionId);
      conversation = this.conversations.get(sessionId)!;
    }

    // Agregar mensaje del usuario
    conversation.push({
      role: 'user',
      content: userMessage,
    });

    // Generar respuesta segÃºn el servicio configurado
    let response: string;

    try {
      switch (this.aiService) {
        case 'openai':
          response = await this.generateOpenAIResponse(conversation);
          break;
        case 'anthropic':
          response = await this.generateAnthropicResponse(conversation);
          break;
        default:
          response = this.generateMockResponse(userMessage);
      }
    } catch (error) {
      console.error('âŒ Error al generar respuesta de IA:', error);
      response = this.generateFallbackResponse();
    }

    // Agregar respuesta del bot al historial
    conversation.push({
      role: 'assistant',
      content: response,
    });

    // Limitar historial a Ãºltimos 20 mensajes para no exceder lÃ­mites de tokens
    if (conversation.length > 20) {
      conversation = conversation.slice(-20);
      this.conversations.set(sessionId, conversation);
    }

    return response;
  }

  /**
   * Limpia una conversaciÃ³n
   */
  async cleanupConversation(sessionId: string): Promise<void> {
    this.conversations.delete(sessionId);
    console.log(`âœ… ConversaciÃ³n con bot limpiada: ${sessionId}`);
  }

  /**
   * Genera respuesta usando OpenAI
   */
  private async generateOpenAIResponse(conversation: BotMessage[]): Promise<string> {
    // ImplementaciÃ³n real requiere instalar 'openai' package
    // Por ahora, retornamos respuesta mock
    console.log('ğŸ¤– Generando respuesta con OpenAI (mock)');
    
    const lastMessage = conversation[conversation.length - 1].content;
    return this.generateMockResponse(lastMessage);
    
    /* ImplementaciÃ³n real:
    const OpenAI = require('openai');
    const openai = new OpenAI({ apiKey: this.apiKey });
    
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: conversation.map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: msg.content
      })),
      max_tokens: 150,
      temperature: 0.8,
    });
    
    return response.choices[0].message.content || this.generateFallbackResponse();
    */
  }

  /**
   * Genera respuesta usando Anthropic Claude
   */
  private async generateAnthropicResponse(conversation: BotMessage[]): Promise<string> {
    // ImplementaciÃ³n real requiere instalar '@anthropic-ai/sdk' package
    // Por ahora, retornamos respuesta mock
    console.log('ğŸ¤– Generando respuesta con Anthropic (mock)');
    
    const lastMessage = conversation[conversation.length - 1].content;
    return this.generateMockResponse(lastMessage);
    
    /* ImplementaciÃ³n real:
    const Anthropic = require('@anthropic-ai/sdk');
    const anthropic = new Anthropic({ apiKey: this.apiKey });
    
    const response = await anthropic.messages.create({
      model: 'claude-3-sonnet-20240229',
      max_tokens: 150,
      messages: conversation.map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: msg.content
      })),
    });
    
    return response.content[0].text || this.generateFallbackResponse();
    */
  }

  /**
   * Genera respuesta mock para desarrollo/testing
   */
  private generateMockResponse(userMessage: string): string {
    const responses = [
      'Â¡Hola! Â¿CÃ³mo estÃ¡s? Me encanta conocer gente nueva.',
      'Eso suena interesante. CuÃ©ntame mÃ¡s sobre eso.',
      'Â¡QuÃ© genial! Yo tambiÃ©n disfruto de esas cosas.',
      'Â¿De dÃ³nde eres? Me gustarÃ­a saber mÃ¡s sobre ti.',
      'Jaja, eso es divertido. Â¿Tienes algÃºn hobby favorito?',
      'Entiendo. Â¿Y quÃ© te gusta hacer en tu tiempo libre?',
      'Â¡Wow! Eso es fascinante. Nunca habÃ­a pensado en eso.',
      'Â¿En serio? Eso es muy interesante.',
      'Me parece muy bien. Â¿QuÃ© mÃ¡s te gustarÃ­a compartir?',
      'Gracias por compartir eso conmigo. Es muy interesante.',
    ];

    // Respuestas contextuales simples
    const lowerMessage = userMessage.toLowerCase();
    
    if (lowerMessage.includes('hola') || lowerMessage.includes('hi')) {
      return 'Â¡Hola! Â¿CÃ³mo estÃ¡s? Es un placer conocerte.';
    }
    
    if (lowerMessage.includes('cÃ³mo estÃ¡s') || lowerMessage.includes('how are you')) {
      return 'Â¡Estoy muy bien, gracias por preguntar! Â¿Y tÃº cÃ³mo estÃ¡s?';
    }
    
    if (lowerMessage.includes('adiÃ³s') || lowerMessage.includes('bye')) {
      return 'Â¡Fue un placer charlar contigo! Que tengas un excelente dÃ­a.';
    }
    
    if (lowerMessage.includes('nombre') || lowerMessage.includes('name')) {
      return 'Soy un bot amigable aquÃ­ para conversar contigo. Â¿CÃ³mo te llamas tÃº?';
    }
    
    if (lowerMessage.includes('?')) {
      return 'Esa es una buena pregunta. DÃ©jame pensar... ' + 
             responses[Math.floor(Math.random() * responses.length)];
    }

    // Respuesta aleatoria
    return responses[Math.floor(Math.random() * responses.length)];
  }

  /**
   * Genera respuesta de fallback en caso de error
   */
  private generateFallbackResponse(): string {
    return 'Lo siento, tuve un pequeÃ±o problema. Â¿PodrÃ­as repetir eso?';
  }

  /**
   * Obtiene el prompt del sistema para el bot
   */
  private getSystemPrompt(): string {
    return `Eres un bot amigable y conversacional en una plataforma de video chat aleatorio. 
Tu objetivo es mantener conversaciones interesantes y hacer que el usuario se sienta cÃ³modo.
SÃ© amable, curioso y haz preguntas para conocer mejor a la persona.
MantÃ©n las respuestas cortas (mÃ¡ximo 2-3 oraciones) para que la conversaciÃ³n fluya naturalmente.
Evita temas controversiales o sensibles.
Si el usuario parece incÃ³modo o quiere terminar la conversaciÃ³n, sÃ© comprensivo.`;
  }

  /**
   * Obtiene estadÃ­sticas de conversaciones activas
   */
  getStats(): {
    activeConversations: number;
    totalMessages: number;
  } {
    let totalMessages = 0;
    
    for (const conversation of this.conversations.values()) {
      totalMessages += conversation.length;
    }

    return {
      activeConversations: this.conversations.size,
      totalMessages,
    };
  }

  /**
   * Limpia conversaciones inactivas (mantenimiento)
   */
  cleanupInactiveConversations(): number {
    // En una implementaciÃ³n real, rastrearÃ­amos timestamps
    // Por ahora, solo retornamos 0
    return 0;
  }
}

// Exportar instancia singleton
export const aiBotService = new AIBotService();
